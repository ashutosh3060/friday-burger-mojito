# -*- coding: utf-8 -*-
"""data_transformation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QVgBxoRwPfIHhnBW0ECT5IiuADGtEbhS
"""
# Libraries
import numpy as np
import pandas as pd

# User-defined Functions
def null_perc_check (df):
    '''
    Calculates missing value count and percentage for all the columns in a dataframe

    Inputs
    -------
    df : dataframe
        The dataframe for which missing value distribution needs to checked

    Output
    -------
    dataframe
        a dataframe showing missing value count and percentage for all the columns
    '''
    missing_value_df = pd.DataFrame(index = df.keys(), data =df.isnull().sum(), columns = ['Missing_Value_Count'])
    missing_value_df['Missing_Value_Percentage'] = np.round(((df.isnull().mean())*100),1)
    sorted_df = missing_value_df.sort_values('Missing_Value_Count',ascending= False)
    return sorted_df

def order_dist_perc_calc(df, unique_id, feature):   
    '''
    Calculates the order % for unique categories from the given independent variable
    
    Inputs
    ----------
    df : dataframe
        The raw dataframe which is used for new feature creation
    unique_id : string
        Unique id name
    feature : string
        Name of the feature for which order % of unique categories need to be calculated

    Output
    -------
    dataframe
        a dataframe showing order percentage of unique categories for each customer
    '''
    feature_grp = df.groupby([unique_id, feature]).agg({feature: 'count'})
    feature_pct = feature_grp.groupby(level=0).apply(lambda x: round(100 * x / float(x.sum()),2))
    feature_pct.rename(columns={feature: f"{feature}_pct"}, inplace=True)
    feature_id = feature_pct.reset_index()
    df_feature_id = pd.DataFrame(feature_id.pivot(index=unique_id, columns=feature, values=f'{feature}_pct'))
    df_feature_id.reset_index()
    df_feature_id = df_feature_id.fillna(0)
    df_feature_id = df_feature_id.apply(pd.to_numeric)
    df_feature_id = df_feature_id.add_prefix(f'{feature}_')
    return df_feature_id

# Define the path, filename
order_path = "/content/"
order_file = "machine_learning_challenge_order_data.csv"
label_path = "/content/"
label_file = "machine_learning_challenge_labeled_data.csv"

# import the dataset as a dataframe
df_order = pd.read_csv(order_path+order_file)
df_label = pd.read_csv(label_path+label_file)

## Create copy of original dataset for new feature creation
df_ftr_crtn = df.copy()
## Typecasting the date field for operation
df_ftr_crtn["order_date"] = pd.to_datetime(df_ftr_crtn["order_date"])

# days before first, last order and period of continuous orders
min_max_order_date = pd.DataFrame(df_ftr_crtn.groupby("customer_id")["order_date"].agg(['min', 'max'])).reset_index()
min_max_order_date["first_order_before"] = (pd.to_datetime('2017-03-01') - min_max_order_date["min"]).dt.days
min_max_order_date["last_order_before"] = (pd.to_datetime('2017-03-01') - min_max_order_date["max"]).dt.days
min_max_order_date["cntns_order_period"] = np.where((min_max_order_date["first_order_before"] - min_max_order_date["last_order_before"])==0, 1, min_max_order_date["first_order_before"] - min_max_order_date["last_order_before"])
min_max_order_date.rename(columns={"min":"first_order_date", "max":"last_order_date"}, inplace=True)

# Number of Failed orders
num_fail_order = pd.DataFrame(df_ftr_crtn.groupby("customer_id")["is_failed"].agg(['sum'])).reset_index()
num_fail_order.rename(columns={"sum":"num_fail_order"}, inplace=True)

df_ftr_crtn = df_ftr_crtn.loc[df_ftr_crtn["is_failed"]==0] #Exclude the customers having all the failed orders

# aggregated field calculation
df_grp_agg = df_ftr_crtn.groupby('customer_id').agg({'order_hour' : lambda x:x.value_counts().index[0], 
                         'customer_order_rank' : 'count', 
                         'voucher_amount' : 'mean',
                         'delivery_fee' : 'mean',
                         'amount_paid' : 'mean',
                         'restaurant_id' : lambda x:x.nunique(),
                         'city_id' : lambda x:x.nunique(),
                         'payment_id' : lambda x:x.nunique(),
                         'platform_id' : lambda x:x.nunique(),
                         'transmission_id' : lambda x:x.nunique()})
df_grp_agg = df_grp_agg.reset_index()
df_grp_agg.rename(columns={"order_hour": "comm_orderhour", "customer_order_rank": "num_success_order",
                           "voucher_amount": "avg_voucher_amnt", "delivery_fee": "avg_deliveryfee",
                           "amount_paid": "avg_amount", "restaurant_id": "num_restaurant",
                           "city_id" : "num_city", "payment_id" : "num_paymentid",
                           "platform_id" : "num_platform", "transmission_id" : "num_transmission"}, inplace=True)

# % Voucher used vs not used
df_ftr_crtn["is_voucher"] = np.where((df_ftr_crtn["voucher_amount"]==0), "0", df_ftr_crtn["voucher_amount"])
df_ftr_crtn["is_voucher"] = np.where((df_ftr_crtn["voucher_amount"]!=0), "1", df_ftr_crtn["is_voucher"])
# Delivery fee charged or not ?
df_ftr_crtn["is_deliveryfee"] = np.where((df_ftr_crtn["delivery_fee"]==0), "0", df_ftr_crtn["delivery_fee"])
df_ftr_crtn["is_deliveryfee"] = np.where((df_ftr_crtn["delivery_fee"]!=0), "1", df_ftr_crtn["is_deliveryfee"])
# Customers who have never paid
df_ftr_crtn["is_amount"] = np.where((df_ftr_crtn["amount_paid"]==0), "0", df_ftr_crtn["amount_paid"])
df_ftr_crtn["is_amount"] = np.where((df_ftr_crtn["amount_paid"]!=0), "1", df_ftr_crtn["is_amount"])

# Create new column for order daytime and define various day-time values
df_ftr_crtn["order_daytime"] = np.where((df_ftr_crtn["order_hour"]>=0)&(df_ftr_crtn["order_hour"]<3), "order_late_night", df_ftr_crtn["order_hour"])
df_ftr_crtn["order_daytime"] = np.where((df_ftr_crtn["order_hour"]>=3)&(df_ftr_crtn["order_hour"]<6), "order_early_morning", df_ftr_crtn["order_daytime"])
df_ftr_crtn["order_daytime"] = np.where((df_ftr_crtn["order_hour"]>=6)&(df_ftr_crtn["order_hour"]<=12), "order_morning", df_ftr_crtn["order_daytime"])
df_ftr_crtn["order_daytime"] = np.where((df_ftr_crtn["order_hour"]>12)&(df_ftr_crtn["order_hour"]<17), "order_afternoon", df_ftr_crtn["order_daytime"])
df_ftr_crtn["order_daytime"] = np.where((df_ftr_crtn["order_hour"]>=17)&(df_ftr_crtn["order_hour"]<21), "order_evening", df_ftr_crtn["order_daytime"])
df_ftr_crtn["order_daytime"] = np.where((df_ftr_crtn["order_hour"]>=21)&(df_ftr_crtn["order_hour"]<=23), "order_night", df_ftr_crtn["order_daytime"])

# % distribution of orders in different day-time
order_daytime_grp = df_ftr_crtn.groupby(["customer_id", "order_daytime"]).agg({"order_daytime": "count"})
order_daytime_pct = order_daytime_grp.groupby(level=0).apply(lambda x:
                                                 round(100 * x / float(x.sum()),2))
order_daytime_pct.rename(columns={"order_daytime": "order_daytime_pct"}, inplace=True)
order_daytime = order_daytime_pct.reset_index()
df_order_daytime = pd.DataFrame(order_daytime.pivot(index="customer_id", columns="order_daytime", values="order_daytime_pct"))
df_order_daytime.reset_index()
df_order_daytime = df_order_daytime.fillna(0)
df_order_daytime = df_order_daytime.apply(pd.to_numeric)

# Create 3 datframes for order % distribution among unique categories for payment_id, platform_id and transmission_id
df_payment_id = order_dist_perc_calc(df_ftr_crtn, "customer_id", "payment_id")
df_platform_id = order_dist_perc_calc(df_ftr_crtn, "customer_id", "platform_id")
df_transmission_id = order_dist_perc_calc(df_ftr_crtn, "customer_id", "transmission_id")

# Create the base dataframe for new features from df_ftr_crtn
df_new_ftr = df_ftr_crtn.drop_duplicates(subset="customer_id", keep="first")[["customer_id", "is_voucher", 

# Left join all the tables with base table (df_new_ftr)
df_new_ftr =  df_new_ftr.merge(min_max_order_date, on='customer_id', how='left').merge(num_fail_order, on='customer_id', how='left')
df_new_ftr =  df_new_ftr.merge(df_grp_agg, on='customer_id', how='left').merge(df_order_daytime, on='customer_id', how='left')
df_new_ftr =  df_new_ftr.merge(df_payment_id, on='customer_id', how='left').merge(df_platform_id, on='customer_id', how='left').merge(df_transmission_id, on='customer_id', how='left')
df_new_ftr =  df_new_ftr.merge(df_label, on='customer_id', how='left')

# Select the order of feature for better readability and ease of analysis
df_new_ftr = df_new_ftr[['customer_id', 'is_returning_customer', 'first_order_before', 'last_order_before', 'cntns_order_period', 
                         'comm_orderhour', 'num_success_order', 'num_fail_order', 
                         'is_voucher', 'avg_voucher_amnt', 'is_deliveryfee', 'avg_deliveryfee', 'is_amount', 'avg_amount', 
                         'num_restaurant', 'num_city', 'num_paymentid', 'num_platform', 'num_transmission', 
                         'order_afternoon', 'order_early_morning', 'order_evening', 'order_late_night', 'order_morning', 'order_night',
                         'payment_id_1491', 'payment_id_1523',
       'payment_id_1619', 'payment_id_1779', 'payment_id_1811',
       'platform_id_525', 'platform_id_22167', 'platform_id_22263',
       'platform_id_22295', 'platform_id_29463', 'platform_id_29495',
       'platform_id_29751', 'platform_id_29815', 'platform_id_30135',
       'platform_id_30199', 'platform_id_30231', 'platform_id_30359',
       'platform_id_30391', 'platform_id_30423', 'transmission_id_212',
       'transmission_id_1988', 'transmission_id_4196', 'transmission_id_4228',
       'transmission_id_4260', 'transmission_id_4324', 'transmission_id_4356',
       'transmission_id_4996', 'transmission_id_21124']].copy()

# Export the dataframe as a csv file
df_new_ftr.to_csv('customer_order_label.csv', index=False)